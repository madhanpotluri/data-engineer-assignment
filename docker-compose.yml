version: '3.8'

services:
  # 1. PostgreSQL Database Service
  postgres:
    image: postgres:13
    container_name: postgres
    ports:
      - "5432:5432"
    env_file:
      - .env
    volumes:
      - postgres-data:/var/lib/postgresql/data

  # 2. Apache Airflow Services
  # We will use the official Airflow image and customize it
  airflow-webserver:
    image: ${AIRFLOW_CUSTOM_IMAGE_NAME:-airflow-local:latest}
    container_name: airflow-webserver
    restart: always
    ports:
      - "8080:8080"
    depends_on:
      - postgres
      - airflow-scheduler
    env_file:
      - .env
    volumes:
      - ./dags:/opt/airflow/dags
      - ./scripts:/opt/airflow/scripts

  airflow-scheduler:
    image: ${AIRFLOW_CUSTOM_IMAGE_NAME:-airflow-local:latest}
    container_name: airflow-scheduler
    restart: always
    depends_on:
      - postgres
    env_file:
      - .env
    volumes:
      - ./dags:/opt/airflow/dags
      - ./scripts:/opt/airflow/scripts

  # 3. Apache Spark Cluster Services
  spark-master:
    image: bitnami/spark:3.5.1
    container_name: spark-master
    command: ["/opt/bitnami/spark/bin/spark-class", "org.apache.spark.deploy.master.Master"]
    ports:
      - "7077:7077"
      - "8081:8080" # Spark UI
    volumes:
      - ./scripts:/scripts
      - ./data:/data

  spark-worker:
    image: bitnami/spark:3.5.1
    container_name: spark-worker-1
    depends_on:
      - spark-master
    command: ["/opt/bitnami/spark/bin/spark-class", "org.apache.spark.deploy.worker.Worker", "spark://spark-master:7077"]
    volumes:
      - ./scripts:/scripts
      - ./data:/data

volumes:
  postgres-data: {}